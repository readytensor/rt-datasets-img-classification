{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ef8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abbus\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6735e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13c2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '.' \n",
    "output_dir = f'./../../processed/{dataset_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90f198",
   "metadata": {},
   "source": [
    "# Process cifar10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49e0bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d3629a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43beeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e3dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared training directory.\n",
      "Cleared testing directory.\n"
     ]
    }
   ],
   "source": [
    "def clear_data_folders(base_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Clears the contents of the training and testing directories within the specified base directory.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The path to the base directory containing 'training' and 'testing' subdirectories.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value but clears specified directories.\n",
    "    \"\"\"\n",
    "    for dataset_type in ['training', 'testing']:\n",
    "        dir_path = os.path.join(base_dir, dataset_type)\n",
    "        # Check if the directory exists\n",
    "        if os.path.exists(dir_path):\n",
    "            # Remove the directory and its contents, then recreate the directory\n",
    "            shutil.rmtree(dir_path)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            print(f\"Cleared {dataset_type} directory.\")\n",
    "        else:\n",
    "            # If the directory does not exist, create it\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            print(f\"Created {dataset_type} directory.\")\n",
    "\n",
    "clear_data_folders(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d274a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save images\n",
    "def save_images(images: np.ndarray, labels: np.ndarray, dataset_type: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves images from the MNIST dataset to disk, organized in directories corresponding to their labels.\n",
    "\n",
    "    This function iterates over images and their corresponding labels, saving each image in a JPEG format\n",
    "    inside a directory structure organized first by dataset type (training or testing), then by class labels.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): A numpy array of images from the MNIST dataset, where each image is represented\n",
    "                             as a 28x28 matrix of pixel values.\n",
    "        labels (np.ndarray): A numpy array of labels corresponding to the images, indicating the digit\n",
    "                             (0 through 9) that each image represents.\n",
    "        dataset_type (str): A string indicating the dataset type, either 'training' or 'testing', which\n",
    "                            is used to organize the saved images into separate directories.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value but saves images to the disk.\n",
    "    \"\"\"\n",
    "    print(f\"Processing images from {dataset_type} set...\")\n",
    "    for idx, (image, label_idx) in enumerate(zip(images, labels)):\n",
    "        # Directory path for the current label\n",
    "        label = idx_to_label[label_idx]\n",
    "        label_dir = os.path.join(output_dir, dataset_type, str(label))\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        # Image file path\n",
    "        image_file = os.path.join(label_dir, f'{idx}.jpg')\n",
    "        # Save the image\n",
    "        img = Image.fromarray(image)\n",
    "        img.save(image_file, 'JPEG')\n",
    "        \n",
    "        if idx > 0 and idx % 5000 == 0: \n",
    "            print(f\"Processed {idx} images.\")\n",
    "    print(f\"Done processing {idx+1} images in {dataset_type} set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bbae13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images from training set...\n",
      "Processed 5000 images.\n",
      "Processed 10000 images.\n",
      "Processed 15000 images.\n",
      "Processed 20000 images.\n",
      "Processed 25000 images.\n",
      "Processed 30000 images.\n",
      "Processed 35000 images.\n",
      "Processed 40000 images.\n",
      "Processed 45000 images.\n",
      "Done processing 50000 images in training set\n",
      "Processing images from testing set...\n",
      "Processed 5000 images.\n",
      "Done processing 10000 images in testing set\n",
      "Images have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Save training images\n",
    "save_images(x_train, y_train, 'training')\n",
    "# Save testing images\n",
    "save_images(x_test, y_test, 'testing')\n",
    "\n",
    "print(\"Images have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8e6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
